{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71bca938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyPDF2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "     ------------------------------------ 232.6/232.6 kB 444.7 kB/s eta 0:00:00\n",
      "Installing collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7f6e803",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "from PyPDF2 import PdfFileReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c33020a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pages: 35\n",
      " \n",
      " \n",
      " Development  Plan for Greater Mumbai 2014‐2034                                                                                                                                                                                                                                                      \n",
      "Acknowledgements  \n",
      "The Consultant  wishes to thank the following  individuals  from the Municipal  Corporation  of \n",
      "Greater Mumbai for their invaluable  support, insights and contributions  towards ‘Working  Paper 1 \n",
      "– Preparation  of Base Map’ for the preparation  of the Development  Plan for Greater Mumbai \n",
      "2014‐34. \n",
      " Mr. Subodh Kumar, IAS, Municipal  Commissioner;  \n",
      " Mr. Rajeev Kuknoor, Chief Engineer Development  Plan; \n",
      " Mr. Sudhir Ghate, Deputy Chief Engineer Development  Plan; \n",
      " Mr. A.G. Marathe, Deputy Chief Engineer Development  Plan; \n",
      " Mr. R. Balachandran,  Executive  Engineer and Town Planning Officer, Development  Plan. \n",
      " Our gratitude  to the following  experts for their invaluable  insights and support: \n",
      " \n",
      "Mr. V.K Phatak, Former Chief Town Planner (MMRDA);  \n",
      " Mr. A.N Kale, Former Chief Engineer, (DP); \n",
      " Mr. A. S Jain Former Dy. Chief Engineer, (DP). \n",
      " We wish to especially  thank MCGM officers, Mr. Jagdish Talreja, Mr. Dinesh Naik, Mr. Hiren \n",
      "Daftardar,  Ms. Anita Naik for their continual  support since the\n",
      " beginning  of the project and their \n",
      "help towards familiarization  and data collection.  They have been instrumental  in helping to \n",
      "contact various MCGM departments  as well as in helping to establish contact with personnel  from \n",
      "other government  departments  and organizations.  Many thanks for the MCGM team, for \n",
      "deploying  personnel,  particularly  Mr. Prasad Gharat, on extensive  field visits that have helped in \n",
      "understanding  actual ground conditions.  \n",
      " \n",
      "We apologize  if we have inadvertently  omitted anyone to whom acknowledgement  is due. We hope \n",
      "and anticipate  the work's usefulness  for the intended purpose. \n",
      " \n"
     ]
    }
   ],
   "source": [
    "#Creating a pdf file object\n",
    "pdf = open(\"file1.pdf\",\"rb\")\n",
    "\n",
    "#creating pdf reader object\n",
    "pdf_reader = PyPDF2.PdfReader(pdf)\n",
    "\n",
    "#checking number of pages in a pdf file\n",
    "print(\"Number of pages:\",len(pdf_reader.pages))\n",
    "\n",
    "#creating a page object\n",
    "page = pdf_reader.pages[1]\n",
    "\n",
    "#finally extracting text from the page\n",
    "print(page.extract_text())\n",
    "\n",
    "#closing the pdf file\n",
    "pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "058d01a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2, urllib , nltk\n",
    "from io import BytesIO\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96535aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "wFile = urllib.request.urlopen('http://www.udri.org/pdf/02%20working%20paper%201.pdf')\n",
    "pdfreader = PyPDF2.PdfReader(BytesIO(wFile.read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "801c38e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting page 2 of the docuemnt\n",
    "pageObj = pdfreader.pages[2]\n",
    "page2 = pageObj.extract_text()\n",
    "\n",
    "#Cleaning the text\n",
    "punctuations = ['(',')',';',':','[',']',',','...','.']\n",
    "tokens = word_tokenize(page2)\n",
    "stop_words = stopwords.words('english')\n",
    "keywords = [word for word in tokens if not word in stop_words and not word in punctuations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cfaa173c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Development',\n",
       " 'Plan',\n",
       " 'Greater',\n",
       " 'Mumbai',\n",
       " '2014‐2034',\n",
       " 'Table',\n",
       " 'Contents',\n",
       " 'The',\n",
       " 'Consultant',\n",
       " 'wishes',\n",
       " 'thank',\n",
       " 'following',\n",
       " 'individuals',\n",
       " 'Municipal',\n",
       " 'Corporation',\n",
       " 'Greater',\n",
       " 'Mumbai',\n",
       " 'invaluable',\n",
       " 'support',\n",
       " 'insights',\n",
       " 'contributions',\n",
       " 'towards',\n",
       " '‘',\n",
       " 'Working',\n",
       " 'Paper',\n",
       " '1',\n",
       " '–',\n",
       " 'Preparation',\n",
       " 'Base',\n",
       " 'Map',\n",
       " '’',\n",
       " 'preparation',\n",
       " 'Development',\n",
       " 'Plan',\n",
       " 'Greater',\n",
       " 'Mumbai',\n",
       " '2014‐34',\n",
       " '.............................................................................................................................',\n",
       " '..............',\n",
       " '3',\n",
       " 'Our',\n",
       " 'gratitude',\n",
       " 'following',\n",
       " 'experts',\n",
       " 'invaluable',\n",
       " 'insights',\n",
       " 'support',\n",
       " '............................',\n",
       " '3',\n",
       " 'We',\n",
       " 'wish',\n",
       " 'especially',\n",
       " 'thank',\n",
       " 'MCGM',\n",
       " 'officers',\n",
       " 'Mr.',\n",
       " 'Jagdish',\n",
       " 'Talreja',\n",
       " 'Mr.',\n",
       " 'Dinesh',\n",
       " 'Naik',\n",
       " 'Mr.',\n",
       " 'Hiren',\n",
       " 'Daftardar',\n",
       " 'Ms.',\n",
       " 'Anita',\n",
       " 'Naik',\n",
       " 'continual',\n",
       " 'support',\n",
       " 'since',\n",
       " 'beginning',\n",
       " 'project',\n",
       " 'help',\n",
       " 'towards',\n",
       " 'familiarization',\n",
       " 'data',\n",
       " 'collection',\n",
       " 'They',\n",
       " 'instrumental',\n",
       " 'helping',\n",
       " 'contact',\n",
       " 'various',\n",
       " 'MCGM',\n",
       " 'departments',\n",
       " 'well',\n",
       " 'helping',\n",
       " 'establish',\n",
       " 'contact',\n",
       " 'personnel',\n",
       " 'government',\n",
       " 'departments',\n",
       " 'organizations',\n",
       " 'Many',\n",
       " 'thanks',\n",
       " 'MCGM',\n",
       " 'team',\n",
       " 'deploying',\n",
       " 'personnel',\n",
       " 'particularly',\n",
       " 'Mr.',\n",
       " 'Prasad',\n",
       " 'Gharat',\n",
       " 'extensive',\n",
       " 'field',\n",
       " 'visits',\n",
       " 'helped',\n",
       " 'understanding',\n",
       " 'actual',\n",
       " 'ground',\n",
       " 'conditions',\n",
       " '........................................................................................',\n",
       " '3',\n",
       " 'BEST',\n",
       " '...............................................................................................................................',\n",
       " '.................',\n",
       " '5',\n",
       " 'Brihanmumbai',\n",
       " 'Electric',\n",
       " 'Supply',\n",
       " 'Transport',\n",
       " 'Undertaking',\n",
       " '..............................................................',\n",
       " '5',\n",
       " 'CIDCO',\n",
       " '...............................................................................................................................',\n",
       " '..............',\n",
       " '5',\n",
       " 'City',\n",
       " 'Industrial',\n",
       " 'Development',\n",
       " 'Corporation',\n",
       " '...............................................................................',\n",
       " '5',\n",
       " 'CTP',\n",
       " '...............................................................................................................................',\n",
       " '..................',\n",
       " '5',\n",
       " 'Comprehensive',\n",
       " 'Transportation',\n",
       " 'Plan',\n",
       " '...............................................................................................',\n",
       " '5',\n",
       " 'DP',\n",
       " '...............................................................................................................................',\n",
       " '....................',\n",
       " '5',\n",
       " 'Development',\n",
       " 'Plan',\n",
       " '..........................................................................................................................',\n",
       " '5',\n",
       " 'DPGM34',\n",
       " '...............................................................................................................................',\n",
       " '..........',\n",
       " '5',\n",
       " 'Development',\n",
       " 'Plan',\n",
       " 'Greater',\n",
       " 'Mumbai',\n",
       " '2034',\n",
       " '.......................................................................................',\n",
       " '5',\n",
       " 'DCR',\n",
       " '...............................................................................................................................',\n",
       " '..................',\n",
       " '5',\n",
       " 'Development',\n",
       " 'Control',\n",
       " 'Regulations',\n",
       " '...................................................................................................',\n",
       " '5',\n",
       " 'DGPS',\n",
       " '...........................................................................................................................',\n",
       " '....................',\n",
       " '5',\n",
       " 'Digital',\n",
       " 'Global',\n",
       " 'Positioning',\n",
       " 'System',\n",
       " '...................................................................................................',\n",
       " '5',\n",
       " 'DPGM',\n",
       " '...............................................................................................................................',\n",
       " '..............',\n",
       " '5',\n",
       " 'Development',\n",
       " 'Plan',\n",
       " 'Greater',\n",
       " 'Mumbai',\n",
       " '...........................................................................................',\n",
       " '5',\n",
       " 'ELU',\n",
       " '...............................................................................................................................',\n",
       " '..................',\n",
       " '5',\n",
       " 'Existing',\n",
       " 'Land',\n",
       " 'use',\n",
       " '.............................................................................................................................',\n",
       " '5',\n",
       " 'FSI',\n",
       " '...............................................................................................................................',\n",
       " '....................',\n",
       " '5',\n",
       " 'Floor',\n",
       " 'Space',\n",
       " 'Index',\n",
       " '............................................................................................................................',\n",
       " '5',\n",
       " 'GIS',\n",
       " '...............................................................................................................................',\n",
       " '...................',\n",
       " '5']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93abf13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mr.Jagdish Talreja', 'Mr.Dinesh Naik', 'Mr.Hiren Daftardar', 'Ms.Anita Naik', 'Mr.Prasad Gharat']\n"
     ]
    }
   ],
   "source": [
    "name_list = list()\n",
    "check =  ['Mr.', 'Mrs.', 'Ms.']\n",
    "for idx, token in enumerate(tokens):\n",
    "    if token.startswith(tuple(check)) and idx < (len(tokens)-1):\n",
    "        name = token + tokens[idx+1] + ' ' +  tokens[idx+2]\n",
    "        name_list.append(name)\n",
    "print(name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "814b5b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "wFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07c0e790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-docx\n",
      "  Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
      "     ------------------------------------ 244.3/244.3 kB 650.2 kB/s eta 0:00:00\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\guna harshitha\\anaconda3\\lib\\site-packages (from python-docx) (4.9.1)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in c:\\users\\guna harshitha\\anaconda3\\lib\\site-packages (from python-docx) (4.12.2)\n",
      "Installing collected packages: python-docx\n",
      "Successfully installed python-docx-1.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "04b39102",
   "metadata": {},
   "outputs": [],
   "source": [
    "import docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f51ed4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a word file object\n",
    "doc = open(\"literature survey.docx\",\"rb\")\n",
    "#creating word reader object\n",
    "document = docx.Document(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "22ccf662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guna Harshitha2211CS020173GammaProblem StatementAn automated NLP-based system can analyze patient-reported symptoms to provide probable disease diagnoses, improving accessibility to preliminary medical guidance, assisting healthcare professionals, and enhancing early disease detection for better patient outcomes.Reference: \" Biomedical Informatics: Computer Applications in Health Care and                                                                                                     Biomedicine \" Literature Survey1. Existing Symptom-Based Diagnosis Systems\n",
      "Several studies and books discuss symptom-based diagnosis systems, including rule-based expert systems and AI-driven models. Traditional medical diagnostic models, such as those discussed in Medical Diagnosis: A Review by Shortlife and Cimino (2014), rely on structured symptom inputs and decision trees. These models use predefined sets of rules and logical conditions to infer possible diseases based on input symptoms. While effective in structured settings, they lack the ability to process unstructured natural language data. Furthermore, expert systems often require manual updating and maintenance, which can be cumbersome as medical knowledge evolves. AI-driven models, including probabilistic approaches like Bayesian networks and machine learning classifiers, have attempted to overcome these limitations. However, many of these systems still depend on structured symptom reporting, limiting their usability in real-world scenarios where patients describe symptoms in diverse and often ambiguous ways.2. Role of NLP in Medical Diagnosis\n",
      "Natural Language Processing (NLP) has emerged as a transformative technology in healthcare applications, enabling the extraction of meaningful information from unstructured medical texts, including electronic health records (EHRs), clinical notes, and patient-reported symptoms. Natural Language Processing in Healthcare by Chapman et al. (2011) provides a foundational understanding of how NLP techniques can be leveraged in healthcare. NLP allows machines to interpret free-text descriptions of symptoms, thereby bridging the gap between patient-reported experiences and structured clinical data. Techniques such as named entity recognition (NER), sentiment analysis, and text classification enable the identification and categorization of symptoms from unstructured text. Recent advancements in deep learning, particularly transformer-based models like BERT and its medical variants (e.g., BioBERT, MedBERT), have significantly improved NLP’s accuracy in medical text analysis, making automated disease diagnosis more feasible.3. Datasets and Tools for Disease Diagnosis\n",
      "The development of robust NLP-based diagnosis systems requires high-quality datasets that map symptoms to diseases. Several publicly available datasets, such as the Medical Symptoms and Diagnosis Database and the Mayo Clinic Disease Dataset, provide essential training data for symptom-based disease prediction models. Books like Machine Learning for Healthcare by Miotto et al. (2018) discuss data-driven approaches to healthcare predictions, emphasizing the importance of large, diverse datasets. In addition to datasets, various NLP frameworks and tools have been utilized in medical text processing. Popular frameworks include:spaCy: A general-purpose NLP library with medical extensions for named entity recognition.BERT and MedBERT: Transformer-based models pretrained on biomedical corpora, enabling contextual understanding of medical texts.Med7: A specialized NLP model designed for extracting medical entities from unstructured text. These tools enable the development of intelligent systems capable of analyzing patient-reported symptoms and predicting probable diseases with greater accuracy than rule-based methods.4. Challenges and Gaps in Existing Research\n",
      "Despite significant advancements, several challenges remain in NLP-based disease diagnosis:Ambiguity in Symptom Description: Patients describe symptoms in varied ways, often using non-standard terminology or vague expressions. Sophisticated NLP models are required to accurately interpret these descriptions and extract relevant medical information.Lack of Comprehensive Datasets: Many available datasets are limited in scope, covering only specific diseases or demographics. Expanding datasets to include diverse patient populations and symptom variations is essential for improving model accuracy.Medical Jargon vs. Layman Terms: Patients often use colloquial terms that differ from professional medical terminology. NLP models must bridge this gap by recognizing synonyms and contextually mapping layman descriptions to medical concepts.Bias in AI Models: AI-based diagnostic models may be biased toward specific demographics if not trained on diverse datasets. Addressing these biases requires careful dataset curation and fairness-aware model training techniques.Explainability and Trust: Medical practitioners and patients need transparent AI-driven diagnostic tools that provide interpretable reasoning for their predictions. Enhancing the explainability of NLP models is a critical area of ongoing research.5. Opportunities for Innovation\n",
      "Given these challenges, several opportunities exist to advance NLP-based symptom-disease diagnosis:Deep Learning Techniques: Transformer-based models, such as GPT-4 and BioBERT, can be further refined for medical applications, improving the accuracy of symptom recognition and disease classification.Multimodal Integration: Combining NLP with other AI techniques, such as computer vision (for medical imaging) and wearable sensor data analysis, can enhance diagnostic capabilities.Voice-Based Symptom Analysis: Integrating NLP with voice recognition can improve accessibility for users with limited literacy or disabilities, allowing them to report symptoms verbally.Real-Time Symptom Tracking: Developing AI-driven chatbots and mobile applications for real-time symptom tracking can facilitate early disease detection and provide users with preliminary medical guidance before they consult a doctor.Collaborative AI-Doctor Systems: NLP models can assist healthcare professionals by summarizing patient symptoms, suggesting probable diagnoses, and cross-referencing medical literature for evidence-based decision-making.Conclusion\n",
      "The literature survey highlights that NLP-based disease diagnosis holds significant promise but requires overcoming key challenges such as data ambiguity, bias, and the need for interpretability. By leveraging advanced NLP techniques, extensive medical datasets, and improved human-AI interaction methods, a robust automated symptom diagnosis system can be developed. Such a system can serve as an initial diagnostic tool, aiding both patients and healthcare professionals in efficient and accurate disease identification. Future research should focus on enhancing model performance, integrating multiple AI modalities, and ensuring fairness and transparency in automated medical diagnostics.\n"
     ]
    }
   ],
   "source": [
    "docu=''\n",
    "for para in document.paragraphs:\n",
    "    docu += para.text\n",
    "print(docu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1cace504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The content of the paragraph 0 is ：Guna Harshitha\n",
      "\n",
      "The content of the paragraph 1 is ：2211CS020173\n",
      "\n",
      "The content of the paragraph 2 is ：Gamma\n",
      "\n",
      "The content of the paragraph 3 is ：\n",
      "\n",
      "The content of the paragraph 4 is ：Problem Statement\n",
      "\n",
      "The content of the paragraph 5 is ：An automated NLP-based system can analyze patient-reported symptoms to provide probable disease diagnoses, improving accessibility to preliminary medical guidance, assisting healthcare professionals, and enhancing early disease detection for better patient outcomes.\n",
      "\n",
      "The content of the paragraph 6 is ：Reference: \" Biomedical Informatics: Computer Applications in Health Care and                                                                                                     Biomedicine \" \n",
      "\n",
      "The content of the paragraph 7 is ：Literature Survey\n",
      "\n",
      "The content of the paragraph 8 is ：1. Existing Symptom-Based Diagnosis Systems\n",
      "Several studies and books discuss symptom-based diagnosis systems, including rule-based expert systems and AI-driven models. Traditional medical diagnostic models, such as those discussed in Medical Diagnosis: A Review by Shortlife and Cimino (2014), rely on structured symptom inputs and decision trees. These models use predefined sets of rules and logical conditions to infer possible diseases based on input symptoms. While effective in structured settings, they lack the ability to process unstructured natural language data. Furthermore, expert systems often require manual updating and maintenance, which can be cumbersome as medical knowledge evolves. AI-driven models, including probabilistic approaches like Bayesian networks and machine learning classifiers, have attempted to overcome these limitations. However, many of these systems still depend on structured symptom reporting, limiting their usability in real-world scenarios where patients describe symptoms in diverse and often ambiguous ways.\n",
      "\n",
      "The content of the paragraph 9 is ：2. Role of NLP in Medical Diagnosis\n",
      "Natural Language Processing (NLP) has emerged as a transformative technology in healthcare applications, enabling the extraction of meaningful information from unstructured medical texts, including electronic health records (EHRs), clinical notes, and patient-reported symptoms. Natural Language Processing in Healthcare by Chapman et al. (2011) provides a foundational understanding of how NLP techniques can be leveraged in healthcare. NLP allows machines to interpret free-text descriptions of symptoms, thereby bridging the gap between patient-reported experiences and structured clinical data. Techniques such as named entity recognition (NER), sentiment analysis, and text classification enable the identification and categorization of symptoms from unstructured text. Recent advancements in deep learning, particularly transformer-based models like BERT and its medical variants (e.g., BioBERT, MedBERT), have significantly improved NLP’s accuracy in medical text analysis, making automated disease diagnosis more feasible.\n",
      "\n",
      "The content of the paragraph 10 is ：3. Datasets and Tools for Disease Diagnosis\n",
      "The development of robust NLP-based diagnosis systems requires high-quality datasets that map symptoms to diseases. Several publicly available datasets, such as the Medical Symptoms and Diagnosis Database and the Mayo Clinic Disease Dataset, provide essential training data for symptom-based disease prediction models. Books like Machine Learning for Healthcare by Miotto et al. (2018) discuss data-driven approaches to healthcare predictions, emphasizing the importance of large, diverse datasets. In addition to datasets, various NLP frameworks and tools have been utilized in medical text processing. Popular frameworks include:\n",
      "\n",
      "The content of the paragraph 11 is ：spaCy: A general-purpose NLP library with medical extensions for named entity recognition.\n",
      "\n",
      "The content of the paragraph 12 is ：BERT and MedBERT: Transformer-based models pretrained on biomedical corpora, enabling contextual understanding of medical texts.\n",
      "\n",
      "The content of the paragraph 13 is ：Med7: A specialized NLP model designed for extracting medical entities from unstructured text. These tools enable the development of intelligent systems capable of analyzing patient-reported symptoms and predicting probable diseases with greater accuracy than rule-based methods.\n",
      "\n",
      "The content of the paragraph 14 is ：4. Challenges and Gaps in Existing Research\n",
      "Despite significant advancements, several challenges remain in NLP-based disease diagnosis:\n",
      "\n",
      "The content of the paragraph 15 is ：Ambiguity in Symptom Description: Patients describe symptoms in varied ways, often using non-standard terminology or vague expressions. Sophisticated NLP models are required to accurately interpret these descriptions and extract relevant medical information.\n",
      "\n",
      "The content of the paragraph 16 is ：Lack of Comprehensive Datasets: Many available datasets are limited in scope, covering only specific diseases or demographics. Expanding datasets to include diverse patient populations and symptom variations is essential for improving model accuracy.\n",
      "\n",
      "The content of the paragraph 17 is ：Medical Jargon vs. Layman Terms: Patients often use colloquial terms that differ from professional medical terminology. NLP models must bridge this gap by recognizing synonyms and contextually mapping layman descriptions to medical concepts.\n",
      "\n",
      "The content of the paragraph 18 is ：Bias in AI Models: AI-based diagnostic models may be biased toward specific demographics if not trained on diverse datasets. Addressing these biases requires careful dataset curation and fairness-aware model training techniques.\n",
      "\n",
      "The content of the paragraph 19 is ：Explainability and Trust: Medical practitioners and patients need transparent AI-driven diagnostic tools that provide interpretable reasoning for their predictions. Enhancing the explainability of NLP models is a critical area of ongoing research.\n",
      "\n",
      "The content of the paragraph 20 is ：5. Opportunities for Innovation\n",
      "Given these challenges, several opportunities exist to advance NLP-based symptom-disease diagnosis:\n",
      "\n",
      "The content of the paragraph 21 is ：Deep Learning Techniques: Transformer-based models, such as GPT-4 and BioBERT, can be further refined for medical applications, improving the accuracy of symptom recognition and disease classification.\n",
      "\n",
      "The content of the paragraph 22 is ：Multimodal Integration: Combining NLP with other AI techniques, such as computer vision (for medical imaging) and wearable sensor data analysis, can enhance diagnostic capabilities.\n",
      "\n",
      "The content of the paragraph 23 is ：Voice-Based Symptom Analysis: Integrating NLP with voice recognition can improve accessibility for users with limited literacy or disabilities, allowing them to report symptoms verbally.\n",
      "\n",
      "The content of the paragraph 24 is ：Real-Time Symptom Tracking: Developing AI-driven chatbots and mobile applications for real-time symptom tracking can facilitate early disease detection and provide users with preliminary medical guidance before they consult a doctor.\n",
      "\n",
      "The content of the paragraph 25 is ：Collaborative AI-Doctor Systems: NLP models can assist healthcare professionals by summarizing patient symptoms, suggesting probable diagnoses, and cross-referencing medical literature for evidence-based decision-making.\n",
      "\n",
      "The content of the paragraph 26 is ：Conclusion\n",
      "The literature survey highlights that NLP-based disease diagnosis holds significant promise but requires overcoming key challenges such as data ambiguity, bias, and the need for interpretability. By leveraging advanced NLP techniques, extensive medical datasets, and improved human-AI interaction methods, a robust automated symptom diagnosis system can be developed. Such a system can serve as an initial diagnostic tool, aiding both patients and healthcare professionals in efficient and accurate disease identification. Future research should focus on enhancing model performance, integrating multiple AI modalities, and ensuring fairness and transparency in automated medical diagnostics.\n",
      "\n",
      "The content of the paragraph 27 is ：\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  output paragraph number and paragraph content \n",
    "for i in range(len(document.paragraphs)):\n",
    "    print(\"The content of the paragraph \"+ str(i)+\" is ：\" + document.paragraphs[i].text+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5ceefa3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bs4\n",
      "  Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\guna harshitha\\anaconda3\\lib\\site-packages (from bs4) (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\guna harshitha\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.3.2.post1)\n",
      "Installing collected packages: bs4\n",
      "Successfully installed bs4-0.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "56bea45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request as urllib2\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f6ff1d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = urllib2.urlopen('https://en.wikipedia.org/wiki/Natural_language_processing')\n",
    "html_doc = response.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "05f2bb73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html class=\"client-nojs vector-feature-language-in-header-enabled vector-feature-language-in-main-page-header-disabled vector-feature-page-tools-pinned-disabled vector-feature-toc-pinned-clientpref-1 vector-feature-main-menu-pinned-disabled vector-feature-limited-width-clientpref-1 vector-feature-limited-width-content-enabled vector-feature-custom-font-size-clientpref-1 vector-feature-appearance-pinned-clientpref-1 vector-feature-night-mode-enabled skin-theme-clientpref-day vector-sticky-header-enabled vector-toc-available\" dir=\"ltr\" lang=\"en\">\n",
      " <head>\n",
      "  <meta charset=\"utf-8\"/>\n",
      "  <title>\n",
      "   Natural language processing - Wikipedia\n",
      "  </title>\n",
      "  <script>\n",
      "   (function(){var className=\"client-js vector-feature-language-in-header-enabled vector-feature-language-in-main-page-header-disabled vector-feature-page-tools-pinned-disabled vector-feature-toc-pinned-clientpref-1 vector-feature-main-menu-pinned-disabled vector-feature-limited-width-clientpref-1 vector-feature-limited-width-content-enabled vector-feature-custom-font-size-clientpref-1 vector-feature-appearance-pinned-clientpref-1 vector-feature-night-mode-enabled skin-theme-clientpref-day vector-sticky-header-enabled vector-toc-available\";var cookie=document.cookie.match(/(?:^|; )enwikimwclientpreferences=([^;]+)/);if(cookie){cookie[1].split('%2C').forEach(function(pref){className=className.replace(new RegExp('(^| )'+pref.replace(/-clientpref-\\w+$|[^\\w-]+/g,'')+'-clientpref-\\\\w+( |$)'),'$1'+pref+'$2');});}document.documentElement.className=className;}());RLCONF={\"wgBreakFrames\":false,\"wgSeparatorTransformTable\":[\"\",\"\"],\"wgDigitTransformTable\":[\"\",\"\"],\"wgDefaultDateFormat\":\"dmy\",\n",
      "\"wgMonthNames\":[\"\",\"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\"July\",\"August\",\"September\",\"October\",\"November\",\"December\"],\"wgRequestId\":\"bb8cccbb-931f-4281-aaf8-3aff8c9effb8\",\"wgCanonicalNamespace\":\"\",\"wgCanonicalSpecialPageName\":false,\"wgNamespaceNumber\":0,\"wgPageName\":\"Natural_language_processing\",\"wgTitle\":\"Natural language processing\",\"wgCurRevisionId\":1274942014,\"wgRevisionId\":1274942014,\"wgArticleId\":21652,\"wgIsArticle\":true,\"wgIsRedirect\":false,\"wgAction\":\"view\",\"wgUserName\":null,\"wgUserGroups\":[\"*\"],\"wgCategories\":[\"All accuracy disputes\",\"Accuracy disputes from December 2013\",\"Harv and Sfn no-target errors\",\"CS1 errors: periodical ignored\",\"CS1 maint: location\",\"Articles with short description\",\"Short description is different from Wikidata\",\"Articles needing additional references from May 2024\",\"All articles needing additional references\",\"All articles with unsourced statements\",\"Articles with unsourced statements from May 2024\",\"Commons category link from Wikidata\",\n",
      "\"Natural language processing\",\"Computational fields of study\",\"Computational linguistics\",\"Speech recognition\"],\"wgPageViewLanguage\":\"en\",\"wgPageContentLanguage\":\"en\",\"wgPageContentModel\":\"wikitext\",\"wgRelevantPageName\":\"Natural_language_processing\",\"wgRelevantArticleId\":21652,\"wgIsProbablyEditable\":true,\"wgRelevantPageIsProbablyEditable\":true,\"wgRestrictionEdit\":[],\"wgRestrictionMove\":[],\"wgNoticeProject\":\"wikipedia\",\"wgCiteReferencePreviewsActive\":false,\"wgFlaggedRevsParams\":{\"tags\":{\"status\":{\"levels\":1}}},\"wgMediaViewerOnClick\":true,\"wgMediaViewerEnabledByDefault\":true,\"wgPopupsFlags\":0,\"wgVisualEditor\":{\"pageLanguageCode\":\"en\",\"pageLanguageDir\":\"ltr\",\"pageVariantFallbacks\":\"en\"},\"wgMFDisplayWikibaseDescriptions\":{\"search\":true,\"watchlist\":true,\"tagline\":false,\"nearby\":true},\"wgWMESchemaEditAttemptStepOversample\":false,\"wgWMEPageLength\":60000,\"wgEditSubmitButtonLabelPublish\":true,\"wgULSPosition\":\"interlanguage\",\"wgULSisCompactLinksEnabled\":false,\"wgVector2022LanguageInHeader\":true,\n",
      "\"wgULSisLanguageSelectorEmpty\":false,\"wgWikibaseItemId\":\"Q30642\",\"wgCheckUserClientHintsHeadersJsApi\":[\"brands\",\"architecture\",\"bitness\",\"fullVersionList\",\"mobile\",\"model\",\"platform\",\"platformVersion\"],\"GEHomepageSuggestedEditsEnableTopics\":true,\"wgGETopicsMatchModeEnabled\":false,\"wgGEStructuredTaskRejectionReasonTextInputEnabled\":false,\"wgGELevelingUpEnabledForUser\":false};RLSTATE={\"ext.globalCssJs.user.styles\":\"ready\",\"site.styles\":\"ready\",\"user.styles\":\"ready\",\"ext.globalCssJs.user\":\"ready\",\"user\":\"ready\",\"user.options\":\"loading\",\"ext.cite.styles\":\"ready\",\"ext.math.styles\":\"ready\",\"skins.vector.search.codex.styles\":\"ready\",\"skins.vector.styles\":\"ready\",\"skins.vector.icons\":\"ready\",\"jquery.makeCollapsible.styles\":\"ready\",\"ext.wikimediamessages.styles\":\"ready\",\"ext.visualEditor.desktopArticleTarget.noscript\":\"ready\",\"ext.uls.interlanguage\":\"ready\",\"wikibase.client.init\":\"ready\",\"ext.wikimediaBadges\":\"ready\"};RLPAGEMODULES=[\"ext.cite.ux-enhancements\",\"ext.scribunto.logs\",\"site\",\n",
      "\"mediawiki.page.ready\",\"jquery.makeCollapsible\",\"mediawiki.toc\",\"skins.vector.js\",\"ext.centralNotice.geoIP\",\"ext.centralNotice.startUp\",\"ext.gadget.ReferenceTooltips\",\"ext.gadget.switcher\",\"ext.urlShortener.toolbar\",\"ext.centralauth.centralautologin\",\"mmv.bootstrap\",\"ext.popups\",\"ext.visualEditor.desktopArticleTarget.init\",\"ext.visu\n"
     ]
    }
   ],
   "source": [
    "#Parsing\n",
    "soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "\n",
    "# Formating the parsed html file\n",
    "strhtm = soup.prettify()\n",
    "\n",
    "# Print few lines\n",
    "print (strhtm[:5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da8c39e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
